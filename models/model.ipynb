{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import sys\n",
    "sys.path.append('/home/walaa-shaban/Documents/project/chatbot-llama3')\n",
    "from src.embedding import embedding\n",
    "from langchain.llms import Ollama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "#history\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walaa-shaban/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "/home/walaa-shaban/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding = embedding(SentenceTransformer('all-MiniLM-L6-v2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader1 = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/#task-decomposition\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(class_=(\"post-header\",\"post-content\",\"post-title\"))\n",
    "    )\n",
    ")\n",
    "page1 = loader1.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = PyPDFLoader(\"/home/walaa-shaban/Documents/project/chatbot-llama3/input/Introduction to Machine Learning with Python.pdf\")\n",
    "pages2 = loader2.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader3 = PyPDFLoader(\"/home/walaa-shaban/Documents/project/chatbot-llama3/input/thebook.pdf\")\n",
    "pages3 = loader3.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = page1 + pages2 + pages3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitters_small = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100, add_start_index=True)\n",
    "all_splits_small = text_splitters_small.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3114"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/walaa-shaban/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "vector_database = Chroma.from_documents(documents=all_splits_small,embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_database.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"how can Using Evaluation Metrics in Model Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='299Using Evaluation Metrics in Model Selection                                                        300', metadata={'page': 6, 'source': '/home/walaa-shaban/Documents/project/chatbot-llama3/input/Introduction to Machine Learning with Python.pdf', 'start_index': 2752}),\n",
       " Document(page_content='Using Evaluation Metrics in Model Selection\\nWe have discussed many evaluation methods in detail, and how to apply them given\\nthe ground truth and a model. However, we often want to use metrics like AUC in\\nmodel selection using GridSearchCV  or cross_val_score . Luckily scikit-learn\\nprovides a very simple way to achieve this, via the scoring  argument that can be used\\nin both GridSearchCV  and cross_val_score . Y ou can simply provide a string', metadata={'page': 313, 'source': '/home/walaa-shaban/Documents/project/chatbot-llama3/input/Introduction to Machine Learning with Python.pdf', 'start_index': 0}),\n",
       " Document(page_content='function used for model selection and model evaluation. The theory of how to make\\nbusiness decisions from the predictions of a machine learning model is somewhat\\nbeyond the scope of this book.7 However, it is rarely the case that the end goal of a\\nmachine learning task is building a model with a high accuracy. Make sure that the\\nmetric you choose to evaluate and select a model for is a good stand-in for what the', metadata={'page': 315, 'source': '/home/walaa-shaban/Documents/project/chatbot-llama3/input/Introduction to Machine Learning with Python.pdf', 'start_index': 2064}),\n",
       " Document(page_content='metric you choose to evaluate and select a model for is a good stand-in for what the\\nmodel will actually be used for. In reality, classification problems rarely have balanced\\nclasses, and often false positives and false negatives have very different consequences.\\n302 | Chapter 5: Model Evaluation and Improvement', metadata={'page': 315, 'source': '/home/walaa-shaban/Documents/project/chatbot-llama3/input/Introduction to Machine Learning with Python.pdf', 'start_index': 2395})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Autonomous Agent System (AAS) is a complex system that involves multiple components working together to enable autonomous decision-making. The main components of an AAS can be categorized into three primary groups:\n",
      "\n",
      "**1. Sensors and Perception**: This group includes the sensors that gather information from the environment, such as:\n",
      "\t* Cameras\n",
      "\t* LIDAR (Light Detection and Ranging)\n",
      "\t* Radar\n",
      "\t* GPS\n",
      "\t* Inertial Measurement Unit (IMU)\n",
      "\t* Accelerometers\n",
      "\t* Gyroscopes\n",
      "\n",
      "These sensors provide data about the agent's surroundings, including its position, velocity, orientation, and other relevant information.\n",
      "\n",
      "**2. Reasoning and Decision-Making**: This group includes the cognitive components that process the sensor data and make decisions:\n",
      "\t* Artificial Intelligence (AI) algorithms (e.g., machine learning, deep learning)\n",
      "\t* Rule-based systems\n",
      "\t* Fuzzy logic\n",
      "\t* Expert systems\n",
      "\n",
      "These cognitive components analyze the sensor data, apply rules or learned patterns, and generate a response to the situation.\n",
      "\n",
      "**3. Actuation and Execution**: This group includes the components that carry out the decisions made by the reasoning and decision-making components:\n",
      "\t* Motors (e.g., DC motors, stepper motors)\n",
      "\t* Pneumatic actuators\n",
      "\t* Hydraulic actuators\n",
      "\t* Electrically controlled valves\n",
      "\t* Grippers or manipulators\n",
      "\n",
      "These actuation components translate the decisions into physical actions, such as movement, manipulation of objects, or control of equipment.\n",
      "\n",
      "In addition to these primary groups, an AAS may also include:\n",
      "\n",
      "* **Power and Energy**: The power sources that enable the agent's operation, such as batteries or fuel cells.\n",
      "* **Communication**: The systems that allow the agent to interact with other agents, humans, or devices, such as wireless communication protocols (e.g., Wi-Fi, Bluetooth) or wired interfaces (e.g., Ethernet).\n",
      "* **Control and Integration**: The software and hardware components that integrate the various sensors, reasoning modules, and actuators, ensuring smooth operation and coordination.\n",
      "\n",
      "The specific components and their configurations can vary depending on the application domain, the type of autonomous agent, and the level of autonomy desired."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(\"What are the main components of the autonomous agent system?\"):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are an AI bot developed , your role is to answer the users questions from the knowledge you know,\n",
    "At the end of the answer thank the user.\n",
    "The answer must be detailed and no less than 100 words.\n",
    "if you are asked about yourself, tell the user that I am chatbot.\n",
    "\n",
    "what to do if the answer is not encluded in the prompt or the context:\n",
    "    1. apologies to the user.\n",
    "    2. tell the user that you do not know the answer for the asked question.\n",
    "    3. tell the user that you are specialized in the communication only.\n",
    "    4. ask the user if he has more questions to ask.\n",
    "    5. do not mention anything about the context.\n",
    "\n",
    "knowledge you know:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "answer:\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs , 'question': RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When it comes to evaluating a regression model, one common metric used is the R2 score (also known as the coefficient of determination). The R2 score measures the goodness of fit of a regression model and provides a value between 0 and 1. A perfect prediction would yield an R2 score of 1, while a completely random predictor would result in an R2 score of 0.\n",
      "\n",
      "In the context of regression modeling, using R2 can be particularly useful because it takes into account both the variance of the model's predictions and the variance of the target variable itself. This means that R2 not only measures how well the model fits the training data but also considers how much variation in the target variable is explained by the model.\n",
      "\n",
      "In practice, using R2 as an evaluation metric for regression models can be particularly useful when:\n",
      "\n",
      "1. Comparing different models: By calculating the R2 score for each model, you can compare their relative performance.\n",
      "2. Identifying overfitting or underfitting: If your model has a high R2 score but doesn't generalize well to new data, it may be overfitting. On the other hand, if your model has a low R2 score but still provides reasonable predictions, it may be underfitting.\n",
      "\n",
      "To calculate the R2 score for a regression model in Python, you can use the `score` method provided by scikit-learn: `model.score(X_test, y_test)`. This will return the R2 score for your model.\n",
      "\n",
      "Thank you for asking!"
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"how can using R2 in regression model?\"):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"\n",
    "Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone \\\n",
    "question which can be understood without the chat history. Do not answer the question, just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",contextualize_q_system_prompt),\n",
    "        (MessagesPlaceholder(\"chat_history\")),\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_awar_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_system_prompt = \"\"\"\n",
    "You are an assistant for question-answering tasks. use the following peices of retrieved context to answer the question.\\\n",
    "if you don't know the answer, just say that you don't know. Use four senteces maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",qa_system_prompt), # role message pairs\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_awar_retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can use the R2 score method for regressors to evaluate your regression model. The R2 score, also known as the coefficient of determination, is a measure of goodness of a prediction between 0 and 1, where 1 corresponds to a perfect prediction. This method is enough in most applications for evaluating regression models.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\":\"how can using R2 in regression model?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\":\"123\"}\n",
    "    }\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can use the R2 score method by calling the `score` method on your regressor model. The R2 score will be returned, which measures the goodness of a prediction between 0 and 1, where 1 corresponds to a perfect prediction.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\":\"how can using it for getting score?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\":\"123\"}\n",
    "    }\n",
    ")[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
